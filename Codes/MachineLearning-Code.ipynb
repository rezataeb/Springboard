{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Science Capstone Project,  Springboard Bootcamp <br> Title: \"Improving Restaurant Reputation Using Yelp User Reviews\" <br> Reza Taeb <br> San Francisco, Spring 2018 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Necessary Packages and Libraries\n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust output view   # May be it can be deleted \n",
    "\n",
    "pd.set_option('display.width', 115)\n",
    "pd.options.display.max_colwidth = 30\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, Let's load the restaurant and review datasets and review datasets that have been modified in the previous parts.    \n",
    "\n",
    "*** (\" restaurant.csv & restaurant_eng.csv & review_restaurant_eng.csv \") ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read cleaned CSV files (\"review_restaurant_eng\", \"restaurant_eng\") \n",
    "\n",
    "df_review_restaurant_eng_processed = pd.read_csv('../review_restaurant_eng_processed.csv')\n",
    "df_review_restaurant_eng_small_processed = pd.read_csv('../review_restaurant_eng_small_processed.csv')\n",
    "df_restaurant_eng = pd.read_csv('../restaurant_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Information of the two datasets : \n",
    "\n",
    "print (df_restaurant_eng.info())\n",
    "print (df_review_restaurant_eng_processed.info())\n",
    "print (df_review_restaurant_eng_small_processed.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "print (df_review_restaurant_eng_small_processed.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 & 4 stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, I am trying to figure out whether we can distinguish the 3 stars and 4 stars reviews by just checking the “text” of reviews or not. Therfore, I am going to focus just on the 3 and 4 stars reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the 3 and 4 star reviews: \n",
    "\n",
    "three_four_star_restaurants = df_review_restaurant_eng_small_processed[df_review_restaurant_eng_small_processed['stars'].isin(['4','3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 3 & 4 star ratings : \n",
    "\n",
    "three_four_star_restaurants.info()\n",
    "print (three_four_star_restaurants.head(5))\n",
    "print (three_four_star_restaurants['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are almost double 4 star entires than 3 star entries, it's better to make the size of them equal (** Under Sampling **) before going through ML algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an equal sample of 3 and 4 star entries \n",
    "\n",
    "no_three_star = len(three_four_star_restaurants[three_four_star_restaurants['stars']==3])\n",
    "four_star_indices =  three_four_star_restaurants[three_four_star_restaurants.stars == 4].index\n",
    "\n",
    "# Random sample of \"4 star\" ratings \n",
    "\n",
    "random_indices = np.random.choice(four_star_indices, no_three_star , replace=False)\n",
    "three_star_indices = three_four_star_restaurants[three_four_star_restaurants.stars == 3].index\n",
    "\n",
    "# Concat 3 stars indices with 4 star ones\n",
    "\n",
    "under_sample_indices = np.concatenate([three_star_indices,random_indices])\n",
    "\n",
    "# Get Balance Dataframe\n",
    "\n",
    "three_four_star_restaurants_balanced = three_four_star_restaurants.loc[under_sample_indices]\n",
    "\n",
    "# check it out \n",
    "\n",
    "print (three_four_star_restaurants_balanced['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define text processing function \n",
    "\n",
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Return the cleaned text as a list of words\n",
    "    '''\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for further steps (Dependent adn Independent variables)\n",
    "\n",
    "X = three_four_star_restaurants_balanced['word_list']\n",
    "y = three_four_star_restaurants_balanced['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation \n",
    "\n",
    "bow_transformer = CountVectorizer().fit(X)\n",
    "X = bow_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Multinomial Naive Bayes ** is a specialised version of Naive Bayes designed more for text documents. Let’s build a Multinomial Naive Bayes model and fit it to our training set (X_train and y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has now been trained! It’s time to see how well it predicts the ratings of previously unseen reviews (reviews from the test set). First, let’s store the predictions as a separate dataframe called ** predicts. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing and evaluating our model\n",
    "\n",
    "predicts = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s evaluate our predictions against the actual ratings (stored in y_test) using confusion_matrix and classification_report from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions against actual ratings \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, predicts))\n",
    "print('\\n \\n')\n",
    "print ('        Classification Report (3 and 4 stars reviews)')\n",
    "print('\\n ')\n",
    "print(classification_report(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 & 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering the 4 and 5 star reviews: \n",
    "\n",
    "four_five_star_restaurants = df_review_restaurant_eng_small_processed[df_review_restaurant_eng_small_processed['stars'].isin(['4','5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 4 & 5 star ratings : \n",
    "\n",
    "print (four_five_star_restaurants['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing ( ** undersampling ** ) the 4 and 5 star ratings entries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an equal sample of 4 and 5 star entries \n",
    "\n",
    "no_four_star = len(four_five_star_restaurants[four_five_star_restaurants['stars']==4])\n",
    "five_star_indices =  four_five_star_restaurants[four_five_star_restaurants.stars == 5].index\n",
    "\n",
    "# Random sample of \"5 star\" ratings \n",
    "\n",
    "random_indices = np.random.choice(five_star_indices, no_four_star , replace=False)\n",
    "four_star_indices = four_five_star_restaurants[four_five_star_restaurants.stars == 4].index\n",
    "\n",
    "# Concat 3 stars indices with 4 star ones\n",
    "\n",
    "under_sample_indices = np.concatenate([four_star_indices,random_indices])\n",
    "\n",
    "# Get Balance Dataframe\n",
    "\n",
    "four_five_star_restaurants_balanced = four_five_star_restaurants.loc[under_sample_indices]\n",
    "\n",
    "# check it out \n",
    "\n",
    "print (four_five_star_restaurants_balanced['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define X and y for further steps \n",
    "\n",
    "X = four_five_star_restaurants_balanced['word_list']\n",
    "y = four_five_star_restaurants_balanced['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorisation \n",
    "\n",
    "bow_transformer = CountVectorizer().fit(X)\n",
    "X = bow_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing and evaluating our model\n",
    "\n",
    "predicts = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions against actual ratings \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, predicts))\n",
    "print('\\n \\n')\n",
    "print ('        Classification Report (4 and 5 stars reviews)')\n",
    "print('\\n ')\n",
    "print(classification_report(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 & 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering the 3 and 5 star reviews: \n",
    "\n",
    "three_five_star_restaurants = df_review_restaurant_eng_small_processed[df_review_restaurant_eng_small_processed['stars'].isin(['3','5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 3 & 5 star ratings : \n",
    "\n",
    "print (three_five_star_restaurants['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing ( ** undersampling ** ) the 3 and 5 star ratings entries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an equal sample of 3 and 5 star entries \n",
    "\n",
    "no_three_star = len(three_five_star_restaurants[three_five_star_restaurants['stars']==3])\n",
    "five_star_indices =  three_five_star_restaurants[three_five_star_restaurants.stars == 5].index\n",
    "\n",
    "# Random sample of \"5 star\" ratings \n",
    "\n",
    "random_indices = np.random.choice(five_star_indices, no_three_star , replace=False)\n",
    "three_star_indices = three_five_star_restaurants[three_five_star_restaurants.stars == 3].index\n",
    "\n",
    "# Concat 3 stars indices with 4 star ones\n",
    "\n",
    "under_sample_indices = np.concatenate([three_star_indices,random_indices])\n",
    "\n",
    "# Get Balance Dataframe\n",
    "\n",
    "three_five_star_restaurants_balanced = three_five_star_restaurants.loc[under_sample_indices]\n",
    "\n",
    "# check it out \n",
    "\n",
    "print (three_five_star_restaurants_balanced['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define X and y for further steps \n",
    "\n",
    "X = three_five_star_restaurants_balanced['word_list']\n",
    "y = three_five_star_restaurants_balanced['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorisation \n",
    "\n",
    "bow_transformer = CountVectorizer().fit(X)\n",
    "X = bow_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing and evaluating our model\n",
    "\n",
    "predicts = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions against actual ratings \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, predicts))\n",
    "print('\\n \\n')\n",
    "print ('        Classification Report (3 and 5 stars reviews)')\n",
    "print('\\n ')\n",
    "print(classification_report(y_test, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
