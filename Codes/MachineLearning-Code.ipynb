{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Science Capstone Project,  Springboard Bootcamp <br> Title: \"Improving Restaurant Reputation Using Yelp User Reviews\" <br> Reza Taeb <br> San Francisco, Spring 2018 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Necessary Packages and Libraries\n",
    "\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust output view   # May be it can be deleted \n",
    "\n",
    "pd.set_option('display.width', 115)\n",
    "pd.options.display.max_colwidth = 30\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, Let's load the restaurant and review datasets and review datasets that have been modified in the previous parts.    \n",
    "\n",
    "*** (\" restaurant.csv & restaurant_eng.csv & review_restaurant_eng.csv \") ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read cleaned CSV files (\"review_restaurant_eng\", \"restaurant_eng\") \n",
    "\n",
    "df_review_restaurant_eng_processed = pd.read_csv('../review_restaurant_eng_processed.csv')\n",
    "df_review_restaurant_eng_small_processed = pd.read_csv('../review_restaurant_eng_small_processed.csv')\n",
    "df_restaurant_eng = pd.read_csv('../restaurant_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48564 entries, 0 to 48563\n",
      "Data columns (total 17 columns):\n",
      "business_id     48564 non-null object\n",
      "name            48564 non-null object\n",
      "neighborhood    22075 non-null object\n",
      "address         48266 non-null object\n",
      "city            48564 non-null object\n",
      "state           48564 non-null object\n",
      "postal_code     48470 non-null object\n",
      "latitude        48564 non-null float64\n",
      "longitude       48564 non-null float64\n",
      "stars           48564 non-null float64\n",
      "review_count    48564 non-null int64\n",
      "is_open         48564 non-null int64\n",
      "attributes      48564 non-null object\n",
      "categories      48564 non-null object\n",
      "hours           48564 non-null object\n",
      "country         48564 non-null object\n",
      "food_type       23281 non-null object\n",
      "dtypes: float64(3), int64(2), object(12)\n",
      "memory usage: 6.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2957735 entries, 0 to 2957734\n",
      "Data columns (total 11 columns):\n",
      "review_id      object\n",
      "user_id        object\n",
      "business_id    object\n",
      "stars          int64\n",
      "date           object\n",
      "text           object\n",
      "useful         float64\n",
      "funny          float64\n",
      "cool           float64\n",
      "word_list      object\n",
      "word_count     int64\n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 248.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14789 entries, 0 to 14788\n",
      "Data columns (total 14 columns):\n",
      "review_id               14789 non-null object\n",
      "user_id                 14789 non-null object\n",
      "business_id             14789 non-null object\n",
      "stars                   14789 non-null int64\n",
      "date                    14789 non-null object\n",
      "text                    14789 non-null object\n",
      "useful                  14789 non-null float64\n",
      "funny                   14789 non-null float64\n",
      "cool                    14789 non-null float64\n",
      "word_list               14789 non-null object\n",
      "word_count              14789 non-null int64\n",
      "text_modified           14789 non-null object\n",
      "Ngrams_list             14789 non-null object\n",
      "ngrams_list_modified    14789 non-null object\n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# General Information of the two datasets : \n",
    "\n",
    "print (df_restaurant_eng.info())\n",
    "print (df_review_restaurant_eng_processed.info())\n",
    "print (df_review_restaurant_eng_small_processed.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  stars        date  \\\n",
      "0  oZf4WJtIdGFbz62mW1qFWA  ngOgZ135Yp2FjRJ_KYgCtg  nDZWoEznY5-oSCc2HvoMtA      1  2014-02-24   \n",
      "1  qj3M6xZeAXDhLXkZv7yVnA  bEKLZqj3gR5zyQDVlquaDg  YRyYbOSwvHkZsZOLv98oQg      1  2012-02-05   \n",
      "2  CdGmiAx-3u-P93PxpqjpSQ  Q8CLfv38ArMpPvv-8Wi-gQ  Qa4eXuZ1IFPwnVXJcpZWtw      4  2013-12-12   \n",
      "3  JpHPWaATFPG8Med9y5aZHw  ZHIMwodx9MIrWbJ8AyUbcg  iUYAqWKoBdHqYNMDzOXb9w      5  2015-04-26   \n",
      "4  Cw5Py-cW1lRB6seZLlWVxQ  zNx6JRMhUHoIhLdKMjN4SA  zaAh8JjNeDyrJXf6xNkdUQ      5  2016-07-15   \n",
      "\n",
      "                            text  useful  funny  cool                      word_list  word_count  \\\n",
      "0  really disappointed in thi...     0.0    0.0   0.0  ['really', 'disappointed',...         193   \n",
      "1  service was terrible had t...     0.0    0.0   0.0  ['service', 'was', 'terrib...          74   \n",
      "2  you probably already know ...     1.0    4.0   0.0  ['you', 'probably', 'alrea...         486   \n",
      "3  simply unbelievable crafts...     1.0    0.0   1.0  ['simply', 'unbelievable',...         160   \n",
      "4  ill keep this short and to...     1.0    1.0   1.0  ['ill', 'keep', 'this', 's...          65   \n",
      "\n",
      "                   text_modified                    Ngrams_list           ngrams_list_modified  \n",
      "0  really disappoint place iv...  [('really', 'disappointed'...  [('really', 'disappoint', ...  \n",
      "1  service terrible wait 45 m...  [('service', 'was', 'terri...  [('service', 'terrible', '...  \n",
      "2  probably already know big ...  [('you', 'probably', 'alre...  [('probably', 'already', '...  \n",
      "3  simply unbelievable crafts...  [('simply', 'unbelievable'...  [('simply', 'unbelievable'...  \n",
      "4  ill keep short point like ...  [('ill', 'keep', 'this', '...  [('ill', 'keep', 'short'),...  \n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "print (df_review_restaurant_eng_small_processed.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 & 4 stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, I am trying to figure out whether we can distinguish the 3 stars and 4 stars reviews by just checking the “text” of reviews or not. Therfore, I am going to focus just on the 3 and 4 stars reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering the 3 and 4 star reviews: \n",
    "\n",
    "three_four_star_restaurants = df_review_restaurant_eng_small_processed[df_review_restaurant_eng_small_processed['stars'].isin(['4','3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6112 entries, 2 to 14788\n",
      "Data columns (total 14 columns):\n",
      "review_id               6112 non-null object\n",
      "user_id                 6112 non-null object\n",
      "business_id             6112 non-null object\n",
      "stars                   6112 non-null int64\n",
      "date                    6112 non-null object\n",
      "text                    6112 non-null object\n",
      "useful                  6112 non-null float64\n",
      "funny                   6112 non-null float64\n",
      "cool                    6112 non-null float64\n",
      "word_list               6112 non-null object\n",
      "word_count              6112 non-null int64\n",
      "text_modified           6112 non-null object\n",
      "Ngrams_list             6112 non-null object\n",
      "ngrams_list_modified    6112 non-null object\n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 716.2+ KB\n",
      "                 review_id                 user_id             business_id  stars        date  \\\n",
      "2   CdGmiAx-3u-P93PxpqjpSQ  Q8CLfv38ArMpPvv-8Wi-gQ  Qa4eXuZ1IFPwnVXJcpZWtw      4  2013-12-12   \n",
      "11  1qtD6lmev0_qT-7RUfNM7A  hZfzVrhsCQ9JDAb2jYoJNQ  Vg1C_1eqwIwkZLIXGMTW3g      4  2012-03-24   \n",
      "12  -7d-4LFSTy18ZQxbrtpXUg  U-nR7ND8CDN2x8ia73CH2Q  QmVF3KJ07PsdroCFwOC_Ow      4  2014-08-22   \n",
      "13  kBaaxRpTgKQ9tEsqXzAEfA  0B-jC1wt-p6jxc4WOb7VOw  eBqGqgZpWuM2dyPRpHbWdg      3  2015-09-30   \n",
      "19  -U_MRMgVgi6_XlFrusOrhw  h6wuKs-PK5R7leh-7Om8lw  VFrSIKxEQvgNowJ0PJxUzA      4  2012-07-30   \n",
      "\n",
      "                             text  useful  funny  cool                      word_list  word_count  \\\n",
      "2   you probably already know ...     1.0    4.0   0.0  ['you', 'probably', 'alrea...         486   \n",
      "11  get past the crowd of unlv...     1.0    0.0   1.0  ['get', 'past', 'the', 'cr...         148   \n",
      "12  the 595 lunch special is w...     1.0    1.0   1.0  ['the', '595', 'lunch', 's...         252   \n",
      "13  service extremely fast and...     1.0    0.0   0.0  ['service', 'extremely', '...          84   \n",
      "19  we tried luckys last night...     1.0    0.0   0.0  ['we', 'tried', 'luckys', ...          76   \n",
      "\n",
      "                    text_modified                    Ngrams_list           ngrams_list_modified  \n",
      "2   probably already know big ...  [('you', 'probably', 'alre...  [('probably', 'already', '...  \n",
      "11  get past crowd unlv studen...  [('get', 'past', 'the', 'c...  [('get', 'past', 'crowd'),...  \n",
      "12  595 lunch special initiall...  [('the', '595', 'lunch', '...  [('595', 'lunch', 'special...  \n",
      "13  service extremely fast rea...  [('service', 'extremely', ...  [('service', 'extremely', ...  \n",
      "19  try luckys last night defi...  [('we', 'tried', 'luckys',...  [('try', 'luckys', 'last')...  \n",
      "4    3987\n",
      "3    2125\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the 3 & 4 star ratings : \n",
    "\n",
    "three_four_star_restaurants.info()\n",
    "print (three_four_star_restaurants.head(5))\n",
    "print (three_four_star_restaurants['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are almost double 4 star entires than 3 star entries, it's better to make the size of them equal (** Under Sampling **) before going through ML algorithm :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    2125\n",
      "4    2125\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make an equal sample of 3 and 4 star entries \n",
    "\n",
    "no_three_star = len(three_four_star_restaurants[three_four_star_restaurants['stars']==3])\n",
    "four_star_indices =  three_four_star_restaurants[three_four_star_restaurants.stars == 4].index\n",
    "\n",
    "# Random sample of \"4 star\" ratings \n",
    "\n",
    "random_indices = np.random.choice(four_star_indices, no_three_star , replace=False)\n",
    "three_star_indices = three_four_star_restaurants[three_four_star_restaurants.stars == 3].index\n",
    "\n",
    "# Concat 3 stars indices with 4 star ones\n",
    "\n",
    "under_sample_indices = np.concatenate([three_star_indices,random_indices])\n",
    "\n",
    "# Get Balance Dataframe\n",
    "\n",
    "three_four_star_restaurants_balanced = three_four_star_restaurants.loc[under_sample_indices]\n",
    "\n",
    "# check it out \n",
    "\n",
    "print (three_four_star_restaurants_balanced['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define text processing function \n",
    "\n",
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Return the cleaned text as a list of words\n",
    "    '''\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define X and y for further steps (Dependent adn Independent variables)\n",
    "\n",
    "X = three_four_star_restaurants_balanced['word_list']\n",
    "y = three_four_star_restaurants_balanced['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorisation \n",
    "\n",
    "bow_transformer = CountVectorizer().fit(X)\n",
    "X = bow_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Multinomial Naive Bayes ** is a specialised version of Naive Bayes designed more for text documents. Let’s build a Multinomial Naive Bayes model and fit it to our training set (X_train and y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has now been trained! It’s time to see how well it predicts the ratings of previously unseen reviews (reviews from the test set). First, let’s store the predictions as a separate dataframe called ** predicts. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing and evaluating our model\n",
    "\n",
    "predicts = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s evaluate our predictions against the actual ratings (stored in y_test) using confusion_matrix and classification_report from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[479 155]\n",
      " [198 443]]\n",
      "\n",
      " \n",
      "\n",
      "        Classification Report (3 and 4 stars reviews)\n",
      "\n",
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.71      0.76      0.73       634\n",
      "          4       0.74      0.69      0.72       641\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions against actual ratings \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print ('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, predicts))\n",
    "print('\\n \\n')\n",
    "print ('        Classification Report (3 and 4 stars reviews)')\n",
    "print('\\n ')\n",
    "print(classification_report(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 & 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering the 4 and 5 star reviews: \n",
    "\n",
    "four_five_star_restaurants = df_review_restaurant_eng_small_processed[df_review_restaurant_eng_small_processed['stars'].isin(['4','5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    5546\n",
      "4    3987\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the 4 & 5 star ratings : \n",
    "\n",
    "print (four_five_star_restaurants['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing ( ** undersampling ** ) the 4 and 5 star ratings entries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    3987\n",
      "4    3987\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make an equal sample of 4 and 5 star entries \n",
    "\n",
    "no_four_star = len(four_five_star_restaurants[four_five_star_restaurants['stars']==4])\n",
    "five_star_indices =  four_five_star_restaurants[four_five_star_restaurants.stars == 5].index\n",
    "\n",
    "# Random sample of \"5 star\" ratings \n",
    "\n",
    "random_indices = np.random.choice(five_star_indices, no_four_star , replace=False)\n",
    "four_star_indices = four_five_star_restaurants[four_five_star_restaurants.stars == 4].index\n",
    "\n",
    "# Concat 3 stars indices with 4 star ones\n",
    "\n",
    "under_sample_indices = np.concatenate([four_star_indices,random_indices])\n",
    "\n",
    "# Get Balance Dataframe\n",
    "\n",
    "four_five_star_restaurants_balanced = four_five_star_restaurants.loc[under_sample_indices]\n",
    "\n",
    "# check it out \n",
    "\n",
    "print (four_five_star_restaurants_balanced['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define X and y for further steps \n",
    "\n",
    "X = four_five_star_restaurants_balanced['word_list']\n",
    "y = four_five_star_restaurants_balanced['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorisation \n",
    "\n",
    "bow_transformer = CountVectorizer().fit(X)\n",
    "X = bow_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing and evaluating our model\n",
    "\n",
    "predicts = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[813 378]\n",
      " [332 870]]\n",
      "\n",
      " \n",
      "\n",
      "        Classification Report (4 and 5 stars reviews)\n",
      "\n",
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          4       0.71      0.68      0.70      1191\n",
      "          5       0.70      0.72      0.71      1202\n",
      "\n",
      "avg / total       0.70      0.70      0.70      2393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions against actual ratings \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print ('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, predicts))\n",
    "print('\\n \\n')\n",
    "print ('        Classification Report (4 and 5 stars reviews)')\n",
    "print('\\n ')\n",
    "print(classification_report(y_test, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 & 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering the 3 and 5 star reviews: \n",
    "\n",
    "three_five_star_restaurants = df_review_restaurant_eng_small_processed[df_review_restaurant_eng_small_processed['stars'].isin(['3','5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    5546\n",
      "3    2125\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the 3 & 5 star ratings : \n",
    "\n",
    "print (three_five_star_restaurants['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing ( ** undersampling ** ) the 3 and 5 star ratings entries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    2125\n",
      "5    2125\n",
      "Name: stars, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make an equal sample of 3 and 5 star entries \n",
    "\n",
    "no_three_star = len(three_five_star_restaurants[three_five_star_restaurants['stars']==3])\n",
    "five_star_indices =  three_five_star_restaurants[three_five_star_restaurants.stars == 5].index\n",
    "\n",
    "# Random sample of \"5 star\" ratings \n",
    "\n",
    "random_indices = np.random.choice(five_star_indices, no_three_star , replace=False)\n",
    "three_star_indices = three_five_star_restaurants[three_five_star_restaurants.stars == 3].index\n",
    "\n",
    "# Concat 3 stars indices with 4 star ones\n",
    "\n",
    "under_sample_indices = np.concatenate([three_star_indices,random_indices])\n",
    "\n",
    "# Get Balance Dataframe\n",
    "\n",
    "three_five_star_restaurants_balanced = three_five_star_restaurants.loc[under_sample_indices]\n",
    "\n",
    "# check it out \n",
    "\n",
    "print (three_five_star_restaurants_balanced['stars'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define X and y for further steps \n",
    "\n",
    "X = three_five_star_restaurants_balanced['word_list']\n",
    "y = three_five_star_restaurants_balanced['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorisation \n",
    "\n",
    "bow_transformer = CountVectorizer().fit(X)\n",
    "X = bow_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing and evaluating our model\n",
    "\n",
    "predicts = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[569  65]\n",
      " [123 518]]\n",
      "\n",
      " \n",
      "\n",
      "        Classification Report (3 and 5 stars reviews)\n",
      "\n",
      " \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.82      0.90      0.86       634\n",
      "          5       0.89      0.81      0.85       641\n",
      "\n",
      "avg / total       0.86      0.85      0.85      1275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions against actual ratings \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print ('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, predicts))\n",
    "print('\\n \\n')\n",
    "print ('        Classification Report (3 and 5 stars reviews)')\n",
    "print('\\n ')\n",
    "print(classification_report(y_test, predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
